{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from dotenv import load_dotenv\n","load_dotenv(\"/mnt/e/working/.env\")\n","import os\n","import datasets\n","data = datasets.load_dataset(\"DataStudio/Vietnamese_Text2Speech_AB0\",\n","                             token=os.getenv(\"HF_AUTH_TOKEN\"))\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/giangtran/miniconda3/envs/llm_local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Predicted class ID: 0\n"]}],"source":["from transformers import HubertForSequenceClassification, AutoProcessor\n","import torch\n","import librosa\n","\n","# Load the processor and model\n","processor = AutoProcessor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n","model = HubertForSequenceClassification.from_pretrained(\"MarekCech/GenreVim-Music-Detection-DistilHuBERT\")\n","model.to(\"cuda\")\n","\n","# Load your audio file\n","file_path = \"/mnt/e/working/vietnamese_tts/data/chunks/nghiep-duyen-17306.0_17078.0.mp3\"\n","file_path = \"/mnt/e/working/vietnamese_tts/data/chunks/nghiep-duyen-2_2681980.0_2705892.0.mp3\"\n","audio, sample_rate = librosa.load(file_path, sr=16000)\n","\n","# Process the audio file\n","inputs = processor(audio, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n","\n","# Move inputs to the same device as the model\n","inputs = {key: value.to(\"cuda\") for key, value in inputs.items()}\n","\n","# Get the model outputs\n","with torch.no_grad():\n","    outputs = model(**inputs)\n","\n","# Process the outputs as needed\n","logits = outputs.logits\n","predicted_class_id = torch.argmax(logits, dim=-1).item()\n","\n","print(f\"Predicted class ID: {predicted_class_id}\")"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"data":{"text/plain":["8706"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["2502 + 3102*2"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"llm_local","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":2}
