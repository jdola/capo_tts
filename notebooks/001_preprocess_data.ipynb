{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chunking audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "from random import choices\n",
    "from silero_vad import load_silero_vad, read_audio, get_speech_timestamps\n",
    "\n",
    "VAD_SAMPLING_RATE = 16000\n",
    "CHUNK_SAMPLING_RATE = 44100\n",
    "\n",
    "model = load_silero_vad()\n",
    "\n",
    "base_data_dir = '/mnt/e/working/vietnamese_tts/data/original'\n",
    "base_chunk_dir = '/mnt/e/working/vietnamese_tts/data/chunks'\n",
    "files = [file for file in os.listdir(base_data_dir) if file.endswith('.mp3')]\n",
    "\n",
    "for file in files:\n",
    "    file_path = os.path.join(base_data_dir, file)\n",
    "    wav = read_audio(file_path) # backend (sox, soundfile, or ffmpeg) required!\n",
    "    speech_timestamps = get_speech_timestamps(wav, model,\n",
    "                                            min_speech_duration_ms=1000,\n",
    "                                            max_speech_duration_s=30,\n",
    "                                            min_silence_duration_ms=300,\n",
    "                                            speech_pad_ms=100)\n",
    "    \n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "    for chunks in speech_timestamps:\n",
    "        start = 1000*chunks['start']/VAD_SAMPLING_RATE\n",
    "        end = 1000*chunks['end']/VAD_SAMPLING_RATE\n",
    "        chunks_path = os.path.join(base_chunk_dir, file.replace('.mp3', f'_{start}_{end}.wav'))\n",
    "        audio[start:end].set_frame_rate(CHUNK_SAMPLING_RATE).export(chunks_path, format='wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transcribe audio chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline, WhisperForConditionalGeneration, WhisperTokenizer, WhisperProcessor\n",
    "\n",
    "MODEL_ID = \"openai/whisper-large-v3\"\n",
    "LANGUAGE = \"vi\"\n",
    "TASK = \"transcribe\"\n",
    "device = \"cuda:0\"\n",
    "\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "tokenizer = WhisperTokenizer.from_pretrained(MODEL_ID, language=LANGUAGE, task=TASK)\n",
    "processor = WhisperProcessor.from_pretrained(MODEL_ID, language=LANGUAGE, task=TASK)\n",
    "#\n",
    "processor.tokenizer.pad_token = processor.tokenizer.eos_token\n",
    "processor.tokenizer.set_prefix_tokens(language=LANGUAGE, task=TASK)\n",
    "\n",
    "model_oai_ft_v3 = WhisperForConditionalGeneration.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch_dtype,\n",
    "    low_cpu_mem_usage=True, \n",
    "    use_safetensors=True,\n",
    ")\n",
    "model_oai_ft_v3 = model_oai_ft_v3.to(device)\n",
    "pipe_oai_ft_v3 = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model_oai_ft_v3,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=256,\n",
    "    chunk_length_s=10,\n",
    "    batch_size=32,\n",
    "    # return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    "    generate_kwargs={\n",
    "        \"task\": \"transcribe\",\n",
    "        \"language\": \"vi\",\n",
    "        \"no_repeat_ngram_size\": 4, # Avoid repetition\n",
    "        \"return_timestamps\": True,\n",
    "        },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, None], [2, 50360]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 16.016644716262817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 180.74905467033386\n",
      "1100 346.78210949897766\n",
      "1200 498.2749969959259\n",
      "1300 648.2184693813324\n",
      "1400 825.8562657833099\n",
      "1500 997.6656391620636\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "base_chunk_dir = '/mnt/e/working/vietnamese_tts/data/chunks'\n",
    "chunks = os.listdir(base_chunk_dir)\n",
    "chunk_paths = [os.path.join(base_chunk_dir, chunk) for chunk in chunks if chunk.endswith('.wav')]\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "start = time.time()\n",
    "for idx,chunk_path in enumerate(chunk_paths):\n",
    "    transcript_path = chunk_path.replace('.wav', '.json')\n",
    "    if os.path.exists(transcript_path):\n",
    "        continue\n",
    "    transcriptions = pipe_oai_ft_v3(chunk_path)\n",
    "    json.dump(transcriptions, open(transcript_path, 'w'))\n",
    "    if idx % 100 == 0:\n",
    "        print(idx, time.time() - start) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# demucs, denoise / filter music chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "EXCLUSIVE_TEXTS = [\n",
    "    \"Hãy subscribe cho kênh Ghiền Mì Gõ\",\n",
    "]\n",
    "pattern = re.compile(\"|\".join(map(re.escape, EXCLUSIVE_TEXTS)))\n",
    "def contains_exclusive_texts(s):\n",
    "    return bool(pattern.search(s))\n",
    "\n",
    "base_chunk_dir = '/mnt/e/working/vietnamese_tts/data/chunks'\n",
    "chunks_files = os.listdir(base_chunk_dir)\n",
    "chunk_audio_paths = [os.path.join(base_chunk_dir, chunk) for chunk in chunks_files if chunk.endswith('.mp3')]\n",
    "transcript_audio_paths = [os.path.join(base_chunk_dir, chunk) for chunk in chunks_files if chunk.endswith('.json')]\n",
    "\n",
    "data = []\n",
    "for audio_file_path in chunk_audio_paths:\n",
    "    tmp_trans_path = audio_file_path.replace('.mp3', '.json')\n",
    "    if tmp_trans_path in transcript_audio_paths:\n",
    "        tmp_spk = audio_file_path.split('/')[-1].split('-')[-0]\n",
    "        text = json.load(open(tmp_trans_path, 'r'))['text']\n",
    "        if not contains_exclusive_texts(text):\n",
    "            data.append(\n",
    "                [\n",
    "                    audio_file_path,\n",
    "                    tmp_spk,\n",
    "                    \"VI-SOUTH\",\n",
    "                    text\n",
    "                ]\n",
    "            )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('/mnt/e/working/vietnamese_tts/data/train_config/metadata.csv', 'w') as f:\n",
    "    writer = csv.writer(f, delimiter=\"|\")\n",
    "    # writer.writerow(['audio', 'speaker', 'language', 'text'])\n",
    "    writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_local",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
