{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388\n",
      "192\n",
      "192\n",
      "768\n",
      "2\n",
      "6\n",
      "3\n",
      "0.1\n",
      "256\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giangtran/miniconda3/envs/melo_env/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/mnt/e/working/vietnamese_tts/melo')\n",
    "from models import SynthesizerTrn, TextEncoder\n",
    "from torch import nn\n",
    "net_g = SynthesizerTrn(388,\n",
    "1025,\n",
    "32,\n",
    "n_speakers=2,\n",
    "mas_noise_scale_initial=0.01,\n",
    "noise_scale_delta=2e-06,\n",
    "**{'use_spk_conditioned_encoder': True, 'use_noise_scaled_mas': True, 'use_mel_posterior_encoder': False, 'use_duration_discriminator': True, 'inter_channels': 192, 'hidden_channels': 192, 'filter_channels': 768, 'n_heads': 2, 'n_layers': 6, 'n_layers_trans_flow': 3, 'kernel_size': 3, 'p_dropout': 0.1, 'resblock': '1', 'resblock_kernel_sizes': [3, 7, 11], 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'upsample_rates': [8, 8, 2, 2, 2], 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [16, 16, 8, 2, 2], 'n_layers_q': 3, 'use_spectral_norm': False, 'gin_channels': 256})\n",
    "net_g_enc_q = TextEncoder(\n",
    "388,\n",
    "192,\n",
    "192,\n",
    "768,\n",
    "2,\n",
    "6,\n",
    "3,\n",
    "0.1,\n",
    "gin_channels=256,\n",
    "num_languages=None,\n",
    "num_tones=None,\n",
    ")\n",
    "emb_g = nn.Embedding(2, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "x = torch.load(\"/mnt/e/working/vietnamese_tts/melo/tmp_test/x.pt\", weights_only=True)\n",
    "x_lengths = torch.load(\"/mnt/e/working/vietnamese_tts/melo/tmp_test/x_lengths.pt\", weights_only=True)\n",
    "spec = torch.load(\"/mnt/e/working/vietnamese_tts/melo/tmp_test/spec.pt\", weights_only=True)\n",
    "spec_lengths = torch.load(\"/mnt/e/working/vietnamese_tts/melo/tmp_test/spec_lengths.pt\", weights_only=True)\n",
    "speakers = torch.load(\"/mnt/e/working/vietnamese_tts/melo/tmp_test/speakers.pt\", weights_only=True)\n",
    "tone = torch.load(\"/mnt/e/working/vietnamese_tts/melo/tmp_test/tone.pt\", weights_only=True)\n",
    "language = torch.load(\"/mnt/e/working/vietnamese_tts/melo/tmp_test/language.pt\", weights_only=True)\n",
    "bert = torch.load(\"/mnt/e/working/vietnamese_tts/melo/tmp_test/bert.pt\", weights_only=True)\n",
    "ja_bert = torch.load(\"/mnt/e/working/vietnamese_tts/melo/tmp_test/ja_bert.pt\", weights_only=True)\n",
    "x = x.to(\"cpu\")\n",
    "x_lengths = x_lengths.to(\"cpu\")\n",
    "spec = spec.to(\"cpu\")\n",
    "spec_lengths = spec_lengths.to(\"cpu\")\n",
    "speakers = speakers.to(\"cpu\")\n",
    "tone = tone.to(\"cpu\")\n",
    "language = language.to(\"cpu\")\n",
    "bert = bert.to(\"cpu\")\n",
    "ja_bert = ja_bert.to(\"cpu\")\n",
    "net_g = net_g.to(\"cpu\")\n",
    "net_g_enc_q = net_g_enc_q.to(\"cpu\")\n",
    "emb_g = emb_g.to(\"cpu\")\n",
    "g = emb_g(speakers).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 14,  0, 14,  0, 15,  0, 14,  0, 14,  0, 14,  0, 14,  0, 15,  0, 14,\n",
       "          0, 15,  0, 14,  0, 15,  0, 14,  0, 14,  0, 15,  0, 14,  0, 14,  0, 18,\n",
       "          0, 14,  0, 16,  0, 14,  0, 14,  0, 19,  0, 14,  0, 14,  0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bert_emb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m net_g_enc_q\u001b[38;5;241m.\u001b[39mtone_emb(tone)\n\u001b[1;32m      3\u001b[0m net_g_enc_q\u001b[38;5;241m.\u001b[39mlanguage_emb(language)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mbert_emb\u001b[49m\n\u001b[1;32m      5\u001b[0m ja_bert_emb\n\u001b[1;32m      6\u001b[0m math\u001b[38;5;241m.\u001b[39msqrt(\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_channels\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bert_emb' is not defined"
     ]
    }
   ],
   "source": [
    "net_g_enc_q.emb(x)\n",
    "net_g_enc_q.tone_emb(tone)\n",
    "net_g_enc_q.language_emb(language)\n",
    "bert_emb\n",
    "ja_bert_emb\n",
    "math.sqrt(\n",
    "    self.hidden_channels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dont get bert emb\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x, m_p, logs_p, x_mask \u001b[38;5;241m=\u001b[39m \u001b[43mnet_g_enc_q\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m            \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mja_bert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/melo_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/melo_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/e/working/vietnamese_tts/melo/models.py:371\u001b[0m, in \u001b[0;36mTextEncoder.forward\u001b[0;34m(self, x, x_lengths, tone, language, bert, ja_bert, g)\u001b[0m\n\u001b[1;32m    367\u001b[0m ja_bert_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mja_bert_proj(ja_bert)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDont get bert emb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    369\u001b[0m x \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memb(x)\n\u001b[0;32m--> 371\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtone_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtone\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlanguage_emb(language)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;241m+\u001b[39m bert_emb\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;241m+\u001b[39m ja_bert_emb\n\u001b[1;32m    375\u001b[0m ) \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_channels\n\u001b[1;32m    377\u001b[0m )  \u001b[38;5;66;03m# [b, t, h]\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDont get x 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    379\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(x, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [b, h, t]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/melo_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/melo_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/melo_env/lib/python3.10/site-packages/torch/nn/modules/sparse.py:164\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/melo_env/lib/python3.10/site-packages/torch/nn/functional.py:2267\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2261\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2262\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2263\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2264\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2265\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2266\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "x, m_p, logs_p, x_mask = net_g_enc_q(\n",
    "            x, x_lengths, tone, language, bert, ja_bert, g=g\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22543/4062162224.py:2: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=False):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with spekers\n",
      "Done do not use vc tensor([[[-4.1581e-01],\n",
      "         [ 3.5135e-02],\n",
      "         [ 2.5942e-01],\n",
      "         [-4.0132e-01],\n",
      "         [ 1.2945e+00],\n",
      "         [ 8.9178e-01],\n",
      "         [-1.0620e+00],\n",
      "         [ 8.0340e-01],\n",
      "         [ 4.1077e-01],\n",
      "         [ 1.1019e+00],\n",
      "         [ 8.7610e-01],\n",
      "         [ 3.1375e-01],\n",
      "         [-4.9503e-01],\n",
      "         [ 4.3753e-01],\n",
      "         [-5.0529e-01],\n",
      "         [-4.3903e-01],\n",
      "         [-5.1217e-01],\n",
      "         [ 1.4721e+00],\n",
      "         [-4.2399e-01],\n",
      "         [-6.2359e-02],\n",
      "         [ 1.8650e+00],\n",
      "         [-2.3406e+00],\n",
      "         [-5.1972e-01],\n",
      "         [-5.1282e-01],\n",
      "         [-9.5541e-01],\n",
      "         [ 3.2500e-01],\n",
      "         [ 4.9130e-02],\n",
      "         [ 6.9914e-01],\n",
      "         [ 1.2553e+00],\n",
      "         [-6.9625e-01],\n",
      "         [-4.1310e-02],\n",
      "         [-2.1498e-01],\n",
      "         [ 9.8868e-01],\n",
      "         [ 7.8500e-01],\n",
      "         [ 2.6427e-01],\n",
      "         [-5.7853e-01],\n",
      "         [-1.1451e-01],\n",
      "         [ 6.1814e-01],\n",
      "         [-7.8632e-01],\n",
      "         [ 7.2646e-02],\n",
      "         [ 2.5611e-01],\n",
      "         [ 4.4229e-02],\n",
      "         [ 7.0059e-01],\n",
      "         [ 1.2137e+00],\n",
      "         [ 2.4571e-01],\n",
      "         [-6.1736e-01],\n",
      "         [ 3.6204e+00],\n",
      "         [-1.3859e-01],\n",
      "         [-9.2674e-01],\n",
      "         [-1.0278e+00],\n",
      "         [-5.2314e-01],\n",
      "         [ 6.0188e-01],\n",
      "         [ 7.1443e-01],\n",
      "         [ 1.2906e-01],\n",
      "         [-1.4850e+00],\n",
      "         [-6.9213e-01],\n",
      "         [-1.4873e+00],\n",
      "         [ 1.1152e+00],\n",
      "         [ 5.3979e-01],\n",
      "         [-3.7196e-02],\n",
      "         [-8.3739e-01],\n",
      "         [-1.0572e-01],\n",
      "         [ 2.2425e-01],\n",
      "         [-1.7601e-01],\n",
      "         [-9.8564e-01],\n",
      "         [ 9.7048e-01],\n",
      "         [-1.4866e+00],\n",
      "         [ 1.4930e+00],\n",
      "         [ 1.4724e+00],\n",
      "         [ 3.2522e-01],\n",
      "         [ 2.6806e-01],\n",
      "         [ 1.2548e+00],\n",
      "         [ 1.3874e-01],\n",
      "         [-1.0111e+00],\n",
      "         [ 3.0443e-01],\n",
      "         [ 1.5209e+00],\n",
      "         [ 6.3429e-01],\n",
      "         [-6.3688e-01],\n",
      "         [ 8.6967e-01],\n",
      "         [ 1.6720e+00],\n",
      "         [-9.3529e-01],\n",
      "         [-2.0235e-01],\n",
      "         [-1.4633e-01],\n",
      "         [ 8.0664e-02],\n",
      "         [-1.2088e-01],\n",
      "         [ 5.6794e-01],\n",
      "         [ 6.4414e-01],\n",
      "         [ 7.5006e-01],\n",
      "         [ 8.6074e-01],\n",
      "         [-4.0624e-01],\n",
      "         [ 6.1877e-02],\n",
      "         [-2.5186e+00],\n",
      "         [ 1.5209e+00],\n",
      "         [-2.2701e-01],\n",
      "         [-1.4171e+00],\n",
      "         [ 1.2998e+00],\n",
      "         [-2.7424e-01],\n",
      "         [ 3.7240e-01],\n",
      "         [-1.3804e+00],\n",
      "         [-6.8104e-01],\n",
      "         [-5.4050e-01],\n",
      "         [-9.8907e-01],\n",
      "         [ 1.2112e-01],\n",
      "         [ 3.4367e-01],\n",
      "         [ 5.8515e-02],\n",
      "         [-2.6921e-01],\n",
      "         [-3.4304e-01],\n",
      "         [ 2.9785e-01],\n",
      "         [ 4.7453e-01],\n",
      "         [ 5.2033e-01],\n",
      "         [-7.2533e-01],\n",
      "         [ 1.8462e+00],\n",
      "         [-1.1965e+00],\n",
      "         [ 1.1956e+00],\n",
      "         [ 5.2685e-01],\n",
      "         [-5.2312e-01],\n",
      "         [-5.9475e-01],\n",
      "         [-6.1114e-01],\n",
      "         [ 1.1335e-01],\n",
      "         [-4.3012e-01],\n",
      "         [ 1.3264e-01],\n",
      "         [ 7.3053e-01],\n",
      "         [ 4.2467e-01],\n",
      "         [-8.0417e-01],\n",
      "         [ 1.0090e+00],\n",
      "         [ 1.0809e+00],\n",
      "         [ 1.0023e-01],\n",
      "         [ 5.0598e-01],\n",
      "         [-2.8880e-01],\n",
      "         [-1.8669e+00],\n",
      "         [ 1.5604e+00],\n",
      "         [-1.1678e+00],\n",
      "         [ 9.8683e-01],\n",
      "         [ 8.5731e-01],\n",
      "         [-6.9452e-01],\n",
      "         [ 3.2862e-01],\n",
      "         [ 2.6867e-01],\n",
      "         [-2.1608e+00],\n",
      "         [-9.7189e-01],\n",
      "         [ 7.8053e-01],\n",
      "         [-3.2614e-01],\n",
      "         [-5.3711e-01],\n",
      "         [ 7.7146e-01],\n",
      "         [ 7.3873e-01],\n",
      "         [ 1.4512e+00],\n",
      "         [ 3.8545e-01],\n",
      "         [-1.7975e-01],\n",
      "         [ 1.9084e-01],\n",
      "         [-4.8936e-01],\n",
      "         [ 3.1985e-01],\n",
      "         [-7.5419e-02],\n",
      "         [ 1.6238e+00],\n",
      "         [ 5.9222e-01],\n",
      "         [ 3.4456e-01],\n",
      "         [-2.7669e-01],\n",
      "         [ 1.0427e+00],\n",
      "         [-4.6371e-01],\n",
      "         [-2.3002e-01],\n",
      "         [ 8.1078e-01],\n",
      "         [ 6.1081e-01],\n",
      "         [-1.5074e+00],\n",
      "         [ 7.0008e-01],\n",
      "         [ 4.1231e-01],\n",
      "         [-2.7270e+00],\n",
      "         [ 2.8308e-01],\n",
      "         [ 1.9190e+00],\n",
      "         [-9.8757e-01],\n",
      "         [ 2.4110e-01],\n",
      "         [-1.3879e+00],\n",
      "         [ 2.4609e+00],\n",
      "         [-2.1067e-01],\n",
      "         [-4.6869e-01],\n",
      "         [-7.4743e-01],\n",
      "         [ 9.4793e-01],\n",
      "         [ 1.3809e-03],\n",
      "         [ 3.4969e-01],\n",
      "         [-1.6436e+00],\n",
      "         [-4.5900e-01],\n",
      "         [ 7.2435e-01],\n",
      "         [ 3.5068e-01],\n",
      "         [-8.9230e-01],\n",
      "         [ 1.2735e+00],\n",
      "         [ 4.0621e-01],\n",
      "         [-6.6306e-01],\n",
      "         [ 9.5529e-01],\n",
      "         [-3.6046e-01],\n",
      "         [ 1.1229e-01],\n",
      "         [ 1.7313e+00],\n",
      "         [-4.2908e-01],\n",
      "         [ 8.7133e-02],\n",
      "         [ 8.8553e-01],\n",
      "         [-9.8853e-01],\n",
      "         [-1.5378e+00],\n",
      "         [ 6.6170e-01],\n",
      "         [-1.0781e+00],\n",
      "         [ 4.2278e-02],\n",
      "         [-2.7298e+00],\n",
      "         [ 4.4114e-01],\n",
      "         [-1.6614e+00],\n",
      "         [-3.3237e-01],\n",
      "         [-6.7394e-01],\n",
      "         [-3.1127e-01],\n",
      "         [-1.0225e+00],\n",
      "         [-5.5945e-01],\n",
      "         [ 2.0085e+00],\n",
      "         [ 1.5289e-01],\n",
      "         [-7.9129e-01],\n",
      "         [-8.3474e-01],\n",
      "         [ 9.7353e-01],\n",
      "         [ 5.5684e-01],\n",
      "         [ 8.6878e-01],\n",
      "         [-5.3637e-01],\n",
      "         [-9.5469e-02],\n",
      "         [ 2.6972e-01],\n",
      "         [-2.1721e+00],\n",
      "         [ 5.4160e-01],\n",
      "         [ 8.3914e-01],\n",
      "         [ 1.9332e-01],\n",
      "         [ 3.0682e-01],\n",
      "         [-8.9031e-01],\n",
      "         [-1.9869e-01],\n",
      "         [ 6.9184e-01],\n",
      "         [-7.2099e-02],\n",
      "         [-3.0009e-01],\n",
      "         [-7.7185e-01],\n",
      "         [-3.9013e-01],\n",
      "         [ 8.5274e-01],\n",
      "         [ 3.2300e-01],\n",
      "         [ 9.4819e-01],\n",
      "         [-1.0664e+00],\n",
      "         [ 6.9786e-01],\n",
      "         [-1.4896e+00],\n",
      "         [-3.3336e+00],\n",
      "         [-4.2500e-01],\n",
      "         [-6.0850e-01],\n",
      "         [ 1.2616e+00],\n",
      "         [-4.4238e-01],\n",
      "         [-9.5293e-01],\n",
      "         [ 9.5525e-01],\n",
      "         [ 7.7846e-01],\n",
      "         [-5.7886e-01],\n",
      "         [-3.9247e-01],\n",
      "         [ 7.8798e-01],\n",
      "         [-3.2854e-01],\n",
      "         [ 6.0418e-02],\n",
      "         [-7.4446e-01],\n",
      "         [ 1.0934e+00],\n",
      "         [ 1.5889e+00],\n",
      "         [ 4.4430e-01],\n",
      "         [-7.6649e-01],\n",
      "         [ 1.6030e+00],\n",
      "         [ 6.4188e-01],\n",
      "         [-1.7151e+00],\n",
      "         [ 5.8864e-01],\n",
      "         [ 1.1793e+00],\n",
      "         [-3.6683e-01]]], grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m net_g\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast(enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m      3\u001b[0m     (\n\u001b[1;32m      4\u001b[0m         y_hat,\n\u001b[1;32m      5\u001b[0m         l_length,\n\u001b[1;32m      6\u001b[0m         attn,\n\u001b[1;32m      7\u001b[0m         ids_slice,\n\u001b[1;32m      8\u001b[0m         x_mask,\n\u001b[1;32m      9\u001b[0m         z_mask,\n\u001b[1;32m     10\u001b[0m         (z, z_p, m_p, logs_p, m_q, logs_q),\n\u001b[1;32m     11\u001b[0m         (hidden_x, logw, logw_),\n\u001b[0;32m---> 12\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43mnet_g\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_lengths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspec_lengths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspeakers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mja_bert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/melo_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/melo_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/e/working/vietnamese_tts/melo/models.py:927\u001b[0m, in \u001b[0;36mSynthesizerTrn.forward\u001b[0;34m(self, x, x_lengths, y, y_lengths, sid, tone, language, bert, ja_bert)\u001b[0m\n\u001b[1;32m    925\u001b[0m     g_p \u001b[38;5;241m=\u001b[39m g\n\u001b[1;32m    926\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone do not use vc\u001b[39m\u001b[38;5;124m\"\u001b[39m, g_p)\n\u001b[0;32m--> 927\u001b[0m x, m_p, logs_p, x_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menc_p\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mja_bert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg_p\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone with enc_p\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    931\u001b[0m z, m_q, logs_q, y_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc_q(y, y_lengths, g\u001b[38;5;241m=\u001b[39mg)\n",
      "File \u001b[0;32m~/miniconda3/envs/melo_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/melo_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/e/working/vietnamese_tts/melo/models.py:370\u001b[0m, in \u001b[0;36mTextEncoder.forward\u001b[0;34m(self, x, x_lengths, tone, language, bert, ja_bert, g)\u001b[0m\n\u001b[1;32m    366\u001b[0m bert_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert_proj(bert)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    367\u001b[0m ja_bert_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mja_bert_proj(ja_bert)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    368\u001b[0m x \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memb(x)\n\u001b[0;32m--> 370\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtone_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtone\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlanguage_emb(language)\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;241m+\u001b[39m bert_emb\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;241m+\u001b[39m ja_bert_emb\n\u001b[1;32m    374\u001b[0m ) \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_channels\n\u001b[1;32m    376\u001b[0m )  \u001b[38;5;66;03m# [b, t, h]\u001b[39;00m\n\u001b[1;32m    377\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(x, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [b, h, t]\u001b[39;00m\n\u001b[1;32m    378\u001b[0m x_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munsqueeze(commons\u001b[38;5;241m.\u001b[39msequence_mask(x_lengths, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m)), \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m    379\u001b[0m     x\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    380\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/melo_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/melo_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/melo_env/lib/python3.10/site-packages/torch/nn/modules/sparse.py:164\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/melo_env/lib/python3.10/site-packages/torch/nn/functional.py:2267\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2261\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2262\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2263\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2264\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2265\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2266\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "\n",
    "net_g.train()\n",
    "with autocast(enabled=False):\n",
    "    (\n",
    "        y_hat,\n",
    "        l_length,\n",
    "        attn,\n",
    "        ids_slice,\n",
    "        x_mask,\n",
    "        z_mask,\n",
    "        (z, z_p, m_p, logs_p, m_q, logs_q),\n",
    "        (hidden_x, logw, logw_),\n",
    "    ) = net_g(\n",
    "        x,\n",
    "        x_lengths,\n",
    "        spec,\n",
    "        spec_lengths,\n",
    "        speakers,\n",
    "        tone,\n",
    "        language,\n",
    "        bert,\n",
    "        ja_bert,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0,   0,   0, 137,   0, 253,   0, 116,   0, 318,   0, 182,   0, 116,\n",
      "           0, 274,   0, 106,   0, 274,   0, 134,   0, 269,   0,  52,   0, 106,\n",
      "           0, 250,   0, 114,   0, 242,   0, 263,   0, 182,   0, 270,   0, 104,\n",
      "           0, 193,   0, 263,   0, 106,   0,   0,   0]])\n",
      "tensor([51])\n",
      "tensor([[[0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],\n",
      "         [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],\n",
      "         [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],\n",
      "         ...,\n",
      "         [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],\n",
      "         [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],\n",
      "         [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010]]])\n",
      "tensor([226])\n",
      "tensor([0])\n",
      "tensor([[ 0, 14,  0, 14,  0, 15,  0, 14,  0, 14,  0, 14,  0, 14,  0, 15,  0, 14,\n",
      "          0, 15,  0, 14,  0, 15,  0, 14,  0, 14,  0, 15,  0, 14,  0, 14,  0, 18,\n",
      "          0, 14,  0, 16,  0, 14,  0, 14,  0, 19,  0, 14,  0, 14,  0]])\n",
      "tensor([[0, 7, 0, 7, 0, 7, 0, 7, 0, 7, 0, 7, 0, 7, 0, 7, 0, 7, 0, 7, 0, 7, 0, 7,\n",
      "         0, 7, 0, 7, 0, 7, 0, 7, 0, 7, 0, 7, 0, 7, 0, 7, 0, 7, 0, 7, 0, 7, 0, 7,\n",
      "         0, 7, 0]])\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "tensor([[[ 0.4616,  0.4616,  0.4616,  ...,  0.0467,  0.4529,  0.4529],\n",
      "         [-0.9904, -0.9904, -0.9904,  ..., -0.7850, -0.3702, -0.3702],\n",
      "         [-0.6036, -0.6036, -0.6036,  ..., -1.0598, -0.0645, -0.0645],\n",
      "         ...,\n",
      "         [ 1.4841,  1.4841,  1.4841,  ...,  1.3933,  0.6678,  0.6678],\n",
      "         [ 1.8793,  1.8793,  1.8793,  ...,  1.5163,  2.1960,  2.1960],\n",
      "         [ 0.6960,  0.6960,  0.6960,  ...,  0.5815,  0.6425,  0.6425]]])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'net_g' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(bert)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(ja_bert)\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mnet_g\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net_g' is not defined"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x_lengths)\n",
    "print(spec)\n",
    "print(spec_lengths)\n",
    "print(speakers)\n",
    "print(tone)\n",
    "print(language)\n",
    "print(bert)\n",
    "print(ja_bert)\n",
    "print(net_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "melo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
